{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport ast\nimport json\nimport glob\nimport torch\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport gc\n#import cudf\nimport joblib\n\nfrom tqdm import tqdm\nfrom datetime import datetime\nfrom collections import Counter\nfrom sklearn import preprocessing\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-12-19T12:36:02.512591Z","iopub.execute_input":"2022-12-19T12:36:02.513217Z","iopub.status.idle":"2022-12-19T12:36:04.328281Z","shell.execute_reply.started":"2022-12-19T12:36:02.513060Z","shell.execute_reply":"2022-12-19T12:36:04.326619Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_w1 = dict()\nlabel_w1 = dict()\n# train_w2 = dict()\n# train_w3 = dict()\n# train_w4 = dict()\n\nfor file in glob.glob(\"/kaggle/input/otto-prep-4-weeks/train_w0_part*.parquet\"):\n   train_w1[file] = pd.read_parquet(file)\ntrain_w1 = pd.concat(train_w1.values())\n\nfor file in glob.glob(\"/kaggle/input/otto-prep-4-weeks/label_w0_part*.parquet\"):\n   label_w1[file] = pd.read_parquet(file)\nlabel_w1 = pd.concat(label_w1.values())\n\n# for file in glob.glob(\"/kaggle/input/otto-training-wo-split/train_w1_part*.parquet\"):\n#    train_w2[file] = pd.read_parquet(file)\n# train_w2 = pd.concat(train_w2.values())\n\n# for file in glob.glob(\"/kaggle/input/otto-training-wo-split/train_w2_part*.parquet\"):\n#    train_w3[file] = pd.read_parquet(file)\n# train_w3 = pd.concat(train_w3.values())\n\n# for file in glob.glob(\"/kaggle/input/otto-training-wo-split/train_w3_part*.parquet\"):\n#    train_w4[file] = pd.read_parquet(file)\n# train_w4 = pd.concat(train_w4.values())\n\n\n#max aid unique 486","metadata":{"execution":{"iopub.status.busy":"2022-12-19T12:36:04.330923Z","iopub.execute_input":"2022-12-19T12:36:04.331857Z","iopub.status.idle":"2022-12-19T12:36:10.066756Z","shell.execute_reply.started":"2022-12-19T12:36:04.331800Z","shell.execute_reply":"2022-12-19T12:36:10.064864Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#label encoding aids\n\ndef get_le():\n    temp_all_data = pd.read_parquet('/kaggle/input/otto-full-optimized-memory-footprint/train.parquet')\n\n\n    le = preprocessing.LabelEncoder()\n    le.fit(temp_all_data['aid'])\n    del temp_all_data\n    return le\n\n\ndef label_encoding(df,le):\n\n\n    df['aid'] = le.transform(df['aid'])\n\n    #set start = 2 to reserve 0 for mask and 1 for pad\n    df['aid+2'] = df['aid']+2\n    df['aid'] = df['aid+2']\n\n    df = df.drop(['aid+2'], axis = 1)\n    joblib.dump(le, 'label_encoder.joblib')\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-12-19T12:36:25.274854Z","iopub.execute_input":"2022-12-19T12:36:25.276152Z","iopub.status.idle":"2022-12-19T12:36:25.286295Z","shell.execute_reply.started":"2022-12-19T12:36:25.276055Z","shell.execute_reply":"2022-12-19T12:36:25.284639Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"le = get_le()\ntrain_w1 = label_encoding(train_w1, le)","metadata":{"execution":{"iopub.status.busy":"2022-12-19T12:36:28.197656Z","iopub.execute_input":"2022-12-19T12:36:28.198126Z","iopub.status.idle":"2022-12-19T12:37:09.385524Z","shell.execute_reply.started":"2022-12-19T12:36:28.198071Z","shell.execute_reply":"2022-12-19T12:37:09.384128Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def get_merged(df, label_df):\n\n    df = pd.DataFrame(df.groupby('session')['aid'].unique().agg(list))\n    label_df = pd.DataFrame(label_df.groupby('session')['aid'].unique().agg(list))\n    \n    df.rename(columns = {'aid': 'input'}, inplace = True)\n    label_df.rename(columns = {'aid': 'label'}, inplace = True)\n\n    df = df.reset_index()\n    label_df = label_df.reset_index()\n\n    df = pd.merge(df, label_df, on = \"session\", how = \"inner\")  \n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-12-19T12:37:09.387978Z","iopub.execute_input":"2022-12-19T12:37:09.388408Z","iopub.status.idle":"2022-12-19T12:37:09.397092Z","shell.execute_reply.started":"2022-12-19T12:37:09.388369Z","shell.execute_reply":"2022-12-19T12:37:09.395942Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_w1 = get_merged(train_w1, label_w1)\ndel label_w1","metadata":{"execution":{"iopub.status.busy":"2022-12-19T12:37:09.398690Z","iopub.execute_input":"2022-12-19T12:37:09.400147Z","iopub.status.idle":"2022-12-19T12:45:15.940924Z","shell.execute_reply.started":"2022-12-19T12:37:09.400032Z","shell.execute_reply":"2022-12-19T12:45:15.939173Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"INPUT_LENGTH = 486\nOUTPUT_LENGTH = 433","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n    def __init__(self, sessions, input_length = INPUT_LENGTH, output_length = OUTPUT_LENGTH):\n        self.sessions = sessions\n        self.input_length = input_length\n        self.output_length = output_length\n        self.history_size = history_size\n\n    def __len__(self):\n        return len(self.sessions)\n    \n    def pad_items(self, session):\n        if len(session)< length:\n            session = session + list(length - len(session) * [0])\n        else: session = session[:length]\n        return session\n      \n    def __getitem__(self, idx):\n        input_tokens = sessions.iloc[idx, sessions.columns.get_loc(\"input\")]\n        input_tokens = pad_items(input, self.input_length) \n        \n        target = sessions.iloc[idx, sessions.columns.get_loc(\"label\")]\n        target = pad_items(target, self.output_length) \n        \n        input_tokens = torch.tensor(input_tokens, dtype=torch.long)\n        target = torch.tensor(target, dtype=torch.long)\n        \n        return input_tokens, target\n                                     ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Recommender(pl.LightningModule):\n    def __init__(\n        self,\n        vocab_size,\n        channels=128,\n        cap=0,\n        mask=1,\n        dropout=0.4,\n        lr=1e-4,\n    ):\n        super().__init__()\n\n        self.cap = cap\n        self.mask = mask\n\n        self.lr = lr\n        self.dropout = dropout\n        self.vocab_size = vocab_size\n\n        self.item_embeddings = torch.nn.Embedding(\n            self.vocab_size, embedding_dim=channels\n        )\n\n        self.input_pos_embedding = torch.nn.Embedding(512, embedding_dim=channels)\n\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=channels, nhead=4, dropout=self.dropout\n        )\n\n        self.encoder = torch.nn.TransformerEncoder(encoder_layer, num_layers=6)\n\n        self.linear_out = Linear(channels, self.vocab_size)\n\n        self.do = nn.Dropout(p=self.dropout)\n\n    def encode_src(self, src_items):\n        src_items = self.item_embeddings(src_items)\n\n        batch_size, in_sequence_len = src_items.size(0), src_items.size(1)\n        pos_encoder = (\n            torch.arange(0, in_sequence_len, device=src_items.device)\n            .unsqueeze(0)\n            .repeat(batch_size, 1)\n        )\n        pos_encoder = self.input_pos_embedding(pos_encoder)\n\n        src_items += pos_encoder\n\n        src = src_items.permute(1, 0, 2)\n\n        src = self.encoder(src)\n\n        return src.permute(1, 0, 2)\n\n    def forward(self, src_items):\n\n        src = self.encode_src(src_items)\n\n        out = self.linear_out(src)\n\n        return out\n\n    def training_step(self, batch, batch_idx):\n        src_items, y_true = batch\n\n        y_pred = self(src_items)\n\n        y_pred = y_pred.view(-1, y_pred.size(2))\n        y_true = y_true.view(-1)\n\n        src_items = src_items.view(-1)\n        mask = src_items == self.mask\n\n        loss = masked_ce(y_pred=y_pred, y_true=y_true, mask=mask)\n        accuracy = masked_accuracy(y_pred=y_pred, y_true=y_true, mask=mask)\n\n        self.log(\"train_loss\", loss)\n        self.log(\"train_accuracy\", accuracy)\n\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        src_items, y_true = batch\n\n        y_pred = self(src_items)\n\n        y_pred = y_pred.view(-1, y_pred.size(2))\n        y_true = y_true.view(-1)\n\n        src_items = src_items.view(-1)\n        mask = src_items == self.mask\n\n        loss = masked_ce(y_pred=y_pred, y_true=y_true, mask=mask)\n        accuracy = masked_accuracy(y_pred=y_pred, y_true=y_true, mask=mask)\n\n        self.log(\"valid_loss\", loss)\n        self.log(\"valid_accuracy\", accuracy)\n\n        return loss\n\n    def test_step(self, batch, batch_idx):\n        src_items, y_true = batch\n\n        y_pred = self(src_items)\n\n        y_pred = y_pred.view(-1, y_pred.size(2))\n        y_true = y_true.view(-1)\n\n        src_items = src_items.view(-1)\n        mask = src_items == self.mask\n\n        loss = masked_ce(y_pred=y_pred, y_true=y_true, mask=mask)\n        accuracy = masked_accuracy(y_pred=y_pred, y_true=y_true, mask=mask)\n\n        self.log(\"test_loss\", loss)\n        self.log(\"test_accuracy\", accuracy)\n\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer, patience=10, factor=0.1\n        )\n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": scheduler,\n            \"monitor\": \"valid_loss\",\n        }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_w1['input'] = train_w1.apply(lambda x: x['aid'] + \n                                      list((TRAIN_HISTORY - len(x['aid'])) * [0]), \n                                      axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_input_target(df, CHUNK = 100000):\n    \n    #train_w_dict = {}\n    it = len(train_w1)//CHUNK +1\n\n    for i in tqdm(range(it)):\n        if i < it-1: temp = df.iloc[i*CHUNK: (i+1)*CHUNK,:].copy()\n        else: temp = df.iloc[i*CHUNK:,:].copy()\n        temp['input'] = temp.apply(lambda x: x['aid'] + \n                                      list((TRAIN_HISTORY - len(x['aid'])) * [0]), \n                                      axis = 1)\n        temp['target'] = temp.apply(lambda x: x['label'] + \n                                      list((PREDICTION_HISTORY - len(x['aid'])) * [0]), \n                                      axis = 1)\n        \n        temp.drop(['aid', 'label'], axis = 1, inplace = True)\n        temp.to_parquet(f'/kaggle/working/input_target_part_{i}.parquet')\n        \n        #train_w_dict[i] = temp\n        \n        del temp\n\n#     for file in glob.glob(\"/kaggle/working/input_target_part_*.parquet\"):\n#        train_w_dict[file] = pd.read_parquet(file)\n    #df = pd.concat(train_w_dict.values())    \n    #return df\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_w1 = get_input_target(train_w1)\nget_input_target(train_w1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_w1\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_w1 = pd.DataFrame()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for file in glob.glob(\"/kaggle/working/input_target_part_*.parquet\"):\n    temp = pd.read_parquet(file)\n    train_w1 = pd.concat([train_w1, temp], ignore_index = True)  \n    del temp\n    gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}