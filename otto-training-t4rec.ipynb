{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport ast\nimport json\nimport glob\nimport torch\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport gc\n#import cudf\nimport joblib\n\nfrom tqdm import tqdm\nfrom datetime import datetime\nfrom collections import Counter\nfrom sklearn import preprocessing\nfrom tqdm import tqdm\n\n\n!pip install polars\n\nimport polars as pl\nimport gensim\nfrom gensim.test.utils import common_texts\nfrom gensim.models import Word2Vec","metadata":{"execution":{"iopub.status.busy":"2022-12-20T16:50:16.898464Z","iopub.execute_input":"2022-12-20T16:50:16.898885Z","iopub.status.idle":"2022-12-20T16:50:34.319633Z","shell.execute_reply.started":"2022-12-20T16:50:16.898802Z","shell.execute_reply":"2022-12-20T16:50:34.318060Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting polars\n  Downloading polars-0.15.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: typing_extensions>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from polars) (4.4.0)\nInstalling collected packages: polars\nSuccessfully installed polars-0.15.7\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"train_w1 = dict()\nlabel_w1 = dict()\n# train_w2 = dict()\n# train_w3 = dict()\n# train_w4 = dict()\n\nfor file in glob.glob(\"/kaggle/input/otto-prep-4-weeks/train_w0_part*.parquet\"):\n   train_w1[file] = pd.read_parquet(file)\ntrain_w1 = pd.concat(train_w1.values())\n\nfor file in glob.glob(\"/kaggle/input/otto-prep-4-weeks/label_w0_part*.parquet\"):\n   label_w1[file] = pd.read_parquet(file)\nlabel_w1 = pd.concat(label_w1.values())\n\n# for file in glob.glob(\"/kaggle/input/otto-training-wo-split/train_w1_part*.parquet\"):\n#    train_w2[file] = pd.read_parquet(file)\n# train_w2 = pd.concat(train_w2.values())\n\n# for file in glob.glob(\"/kaggle/input/otto-training-wo-split/train_w2_part*.parquet\"):\n#    train_w3[file] = pd.read_parquet(file)\n# train_w3 = pd.concat(train_w3.values())\n\n# for file in glob.glob(\"/kaggle/input/otto-training-wo-split/train_w3_part*.parquet\"):\n#    train_w4[file] = pd.read_parquet(file)\n# train_w4 = pd.concat(train_w4.values())\n\n\n#max aid unique 486","metadata":{"execution":{"iopub.status.busy":"2022-12-20T16:50:34.321755Z","iopub.execute_input":"2022-12-20T16:50:34.322434Z","iopub.status.idle":"2022-12-20T16:50:43.784247Z","shell.execute_reply.started":"2022-12-20T16:50:34.322400Z","shell.execute_reply":"2022-12-20T16:50:43.783458Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\n\n#label encoding not required\n\n# def get_le():\n#     temp_all_data = pd.read_parquet('/kaggle/input/otto-full-optimized-memory-footprint/train.parquet')\n\n\n#     le = preprocessing.LabelEncoder()\n#     le.fit(temp_all_data['aid'])\n#     del temp_all_data\n#     return le\n\n\ndef label_encoding(df):\n\n    #set start = 2 to reserve 0 for mask and 1 for pad\n    df['aid+2'] = df['aid']+2\n    df['aid'] = df['aid+2']\n\n    df = df.drop(['aid+2'], axis = 1)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-12-20T16:50:43.785231Z","iopub.execute_input":"2022-12-20T16:50:43.785643Z","iopub.status.idle":"2022-12-20T16:50:43.792407Z","shell.execute_reply.started":"2022-12-20T16:50:43.785619Z","shell.execute_reply":"2022-12-20T16:50:43.791579Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_w1 = label_encoding(train_w1)","metadata":{"execution":{"iopub.status.busy":"2022-12-20T16:50:43.794241Z","iopub.execute_input":"2022-12-20T16:50:43.795961Z","iopub.status.idle":"2022-12-20T16:51:25.919285Z","shell.execute_reply.started":"2022-12-20T16:50:43.795906Z","shell.execute_reply":"2022-12-20T16:51:25.917159Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def get_merged(df, label_df):\n\n    df = pd.DataFrame(df.groupby('session')['aid'].unique().agg(list))\n    label_df = pd.DataFrame(label_df.groupby('session')['aid'].unique().agg(list))\n    \n    df.rename(columns = {'aid': 'input'}, inplace = True)\n    label_df.rename(columns = {'aid': 'label'}, inplace = True)\n\n    df = df.reset_index()\n    label_df = label_df.reset_index()\n\n    df = pd.merge(df, label_df, on = \"session\", how = \"inner\")  \n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-12-20T16:51:25.920724Z","iopub.execute_input":"2022-12-20T16:51:25.921112Z","iopub.status.idle":"2022-12-20T16:51:25.929201Z","shell.execute_reply.started":"2022-12-20T16:51:25.921079Z","shell.execute_reply":"2022-12-20T16:51:25.928066Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_w1 = get_merged(train_w1, label_w1)\ndel label_w1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get W2Vec embeddings\n\n# train = pl.read_parquet('../input/otto-full-optimized-memory-footprint/train.parquet')\n# test = pl.read_parquet('../input/otto-full-optimized-memory-footprint/test.parquet')\n\n# pl.concat([train, test]).groupby('session').agg(\n#     pl.col('aid').alias('sentence'))\n\n# sentences_df = pl.concat([train, test]).groupby('session').agg(\n#     pl.col('aid').alias('sentence')\n# )\n\n# sentences = sentences_df['sentence'].to_list()\n\n# w2vec = Word2Vec(sentences=sentences, vector_size=32, min_count=1, workers=4)\n\n\n#load from dataset\n\n\n\n# Load pre-trained Word2Vec model.\nw2v = gensim.models.Word2Vec.load(\"/kaggle/input/otto-w2vec/word2vec.model\")\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-20T16:51:25.930476Z","iopub.execute_input":"2022-12-20T16:51:25.930844Z","iopub.status.idle":"2022-12-20T16:51:50.163950Z","shell.execute_reply.started":"2022-12-20T16:51:25.930809Z","shell.execute_reply":"2022-12-20T16:51:50.162442Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"w2v.wv[1517087, 1563461]","metadata":{"execution":{"iopub.status.busy":"2022-12-20T18:05:06.879305Z","iopub.execute_input":"2022-12-20T18:05:06.879674Z","iopub.status.idle":"2022-12-20T18:05:06.888964Z","shell.execute_reply.started":"2022-12-20T18:05:06.879645Z","shell.execute_reply":"2022-12-20T18:05:06.887756Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"array([[-0.20965268, -0.3161569 ,  0.16568755,  0.13269655, -0.03142752,\n         0.0010279 ,  0.14203872,  0.09813991, -0.01216098,  0.11770962,\n         0.05917775, -0.13912615, -0.00406223, -0.21008135, -0.07842495,\n         0.01669407,  0.00154324,  0.0625506 ,  0.11380144,  0.18857571,\n         0.20057896,  0.23885112,  0.3208806 , -0.05481645,  0.29093567,\n        -0.05895341, -0.06576372,  0.07176089, -0.02688283,  0.04902829,\n        -0.0235942 ,  0.09737678],\n       [-0.1144049 , -0.22020069,  0.3096514 ,  0.00969114, -0.0637967 ,\n        -0.12693761,  0.3253206 ,  0.09385355, -0.22085038,  0.12707634,\n         0.08991524, -0.26834506, -0.15201019, -0.06641769, -0.19265038,\n        -0.13718845, -0.23630604,  0.46609965, -0.06677192,  0.15155347,\n         0.21610178,  0.35841957,  0.40299895, -0.07202827,  0.26018897,\n        -0.21138193, -0.05013152, -0.02773231,  0.07015457, -0.18631922,\n        -0.15811223,  0.18763006]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"train_w1","metadata":{"execution":{"iopub.status.busy":"2022-12-20T17:45:15.107113Z","iopub.execute_input":"2022-12-20T17:45:15.107522Z","iopub.status.idle":"2022-12-20T17:45:15.127000Z","shell.execute_reply.started":"2022-12-20T17:45:15.107490Z","shell.execute_reply":"2022-12-20T17:45:15.126220Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"         session                                              input  \\\n0              0  [1517087, 1563461, 1309448, 16248, 1781824, 11...   \n1              1                                           [424966]   \n2              2                                           [763745]   \n3              3  [1425969, 1343408, 1815572, 287010, 1809573, 1...   \n4              4                                   [613621, 298829]   \n...          ...                                                ...   \n4441137  5348699                                          [1083667]   \n4441138  5348703                                          [1497091]   \n4441139  5348707                                           [688769]   \n4441140  5348718                                           [974127]   \n4441141  5348719                                           [838780]   \n\n                                                     label  \n0              [1816325, 984597, 1072782, 173702, 1407538]  \n1        [1492293, 910862, 1491172, 424964, 1515526, 44...  \n2          [137492, 504789, 795863, 378348, 26638, 817441]  \n3        [357461, 984459, 622368, 578649, 1253857, 1660...  \n4                                                 [298827]  \n...                                                    ...  \n4441137                                          [1211923]  \n4441138                                          [1764745]  \n4441139                                          [1453498]  \n4441140                                           [974125]  \n4441141                                           [594274]  \n\n[4441142 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>session</th>\n      <th>input</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>[1517087, 1563461, 1309448, 16248, 1781824, 11...</td>\n      <td>[1816325, 984597, 1072782, 173702, 1407538]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>[424966]</td>\n      <td>[1492293, 910862, 1491172, 424964, 1515526, 44...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>[763745]</td>\n      <td>[137492, 504789, 795863, 378348, 26638, 817441]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>[1425969, 1343408, 1815572, 287010, 1809573, 1...</td>\n      <td>[357461, 984459, 622368, 578649, 1253857, 1660...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>[613621, 298829]</td>\n      <td>[298827]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4441137</th>\n      <td>5348699</td>\n      <td>[1083667]</td>\n      <td>[1211923]</td>\n    </tr>\n    <tr>\n      <th>4441138</th>\n      <td>5348703</td>\n      <td>[1497091]</td>\n      <td>[1764745]</td>\n    </tr>\n    <tr>\n      <th>4441139</th>\n      <td>5348707</td>\n      <td>[688769]</td>\n      <td>[1453498]</td>\n    </tr>\n    <tr>\n      <th>4441140</th>\n      <td>5348718</td>\n      <td>[974127]</td>\n      <td>[974125]</td>\n    </tr>\n    <tr>\n      <th>4441141</th>\n      <td>5348719</td>\n      <td>[838780]</td>\n      <td>[594274]</td>\n    </tr>\n  </tbody>\n</table>\n<p>4441142 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"INPUT_LENGTH = 100\nOUTPUT_LENGTH = 20","metadata":{"execution":{"iopub.status.busy":"2022-12-20T14:15:57.183052Z","iopub.execute_input":"2022-12-20T14:15:57.183620Z","iopub.status.idle":"2022-12-20T14:15:57.190575Z","shell.execute_reply.started":"2022-12-20T14:15:57.183572Z","shell.execute_reply":"2022-12-20T14:15:57.189257Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n    def __init__(self, sessions, input_length = INPUT_LENGTH, output_length = OUTPUT_LENGTH):\n        self.sessions = sessions\n        self.input_length = input_length\n        self.output_length = output_length\n\n    def __len__(self):\n        return len(self.sessions)\n    \n    def pad_items(self, session, length):\n        if len(session)< length:\n            session = session + list(length - len(session) * [0])\n        else: session = session[-length:]\n        return session\n      \n    def __getitem__(self, idx):\n        input_tokens = sessions.iloc[idx, sessions.columns.get_loc(\"input\")]\n        input_tokens = pad_items(input, self.input_length) \n        \n        target = sessions.iloc[idx, sessions.columns.get_loc(\"label\")]\n        target = pad_items(target, self.output_length) \n        \n        input_tokens = torch.tensor(input_tokens, dtype=torch.long)\n        target = torch.tensor(target, dtype=torch.long)\n        \n        return input_tokens, target\n                                     ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Recommender(pl.LightningModule):\n    def __init__(\n        self,\n        out = OUTPUT_LENGTH,\n        channels=INPUT_LENGTH,\n        cap=0,\n        mask=1,\n        dropout=0.2,\n        lr=1e-4,\n        word2vec = w2v\n    ):\n        super().__init__()\n\n#         self.cap = cap\n#         self.mask = mask\n\n#         self.lr = lr\n#         self.dropout = dropout\n#         self.vocab_size = vocab_size\n\n        self.item_embeddings = w2v\n\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=channels, nhead=4, dropout=self.dropout\n        )\n\n        self.encoder = torch.nn.TransformerEncoder(encoder_layer, num_layers=10)\n\n        self.linear_out = Linear(channels, self.out)\n\n        self.do = nn.Dropout(p=self.dropout)\n\n    def encode_src(self, src_items):\n        src_items = self.item_embeddings(src_items)\n\n        batch_size, in_sequence_len = src_items.size(0), src_items.size(1)\n        pos_encoder = (\n            torch.arange(0, in_sequence_len, device=src_items.device)\n            .unsqueeze(0)\n            .repeat(batch_size, 1)\n        )\n        pos_encoder = self.input_pos_embedding(pos_encoder)\n\n        src_items += pos_encoder\n\n        src = src_items.permute(1, 0, 2)\n\n        src = self.encoder(src)\n\n        return src.permute(1, 0, 2)\n\n    def forward(self, src_items):\n\n        src = self.encode_src(src_items)\n\n        out = self.linear_out(src)\n\n        return out\n\n    def training_step(self, batch, batch_idx):\n        src_items, y_true = batch\n\n        y_pred = self(src_items)\n\n        y_pred = y_pred.view(-1, y_pred.size(2))\n        y_true = y_true.view(-1)\n\n        src_items = src_items.view(-1)\n        mask = src_items == self.mask\n\n        loss = masked_ce(y_pred=y_pred, y_true=y_true, mask=mask)\n        accuracy = masked_accuracy(y_pred=y_pred, y_true=y_true, mask=mask)\n\n        self.log(\"train_loss\", loss)\n        self.log(\"train_accuracy\", accuracy)\n\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        src_items, y_true = batch\n\n        y_pred = self(src_items)\n\n        y_pred = y_pred.view(-1, y_pred.size(2))\n        y_true = y_true.view(-1)\n\n        src_items = src_items.view(-1)\n        mask = src_items == self.mask\n\n        loss = masked_ce(y_pred=y_pred, y_true=y_true, mask=mask)\n        accuracy = masked_accuracy(y_pred=y_pred, y_true=y_true, mask=mask)\n\n        self.log(\"valid_loss\", loss)\n        self.log(\"valid_accuracy\", accuracy)\n\n        return loss\n\n    def test_step(self, batch, batch_idx):\n        src_items, y_true = batch\n\n        y_pred = self(src_items)\n\n        y_pred = y_pred.view(-1, y_pred.size(2))\n        y_true = y_true.view(-1)\n\n        src_items = src_items.view(-1)\n        mask = src_items == self.mask\n\n        loss = masked_ce(y_pred=y_pred, y_true=y_true, mask=mask)\n        accuracy = masked_accuracy(y_pred=y_pred, y_true=y_true, mask=mask)\n\n        self.log(\"test_loss\", loss)\n        self.log(\"test_accuracy\", accuracy)\n\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer, patience=10, factor=0.1\n        )\n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": scheduler,\n            \"monitor\": \"valid_loss\",\n        }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_w1['input'] = train_w1.apply(lambda x: x['aid'] + \n                                      list((TRAIN_HISTORY - len(x['aid'])) * [0]), \n                                      axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_input_target(df, CHUNK = 100000):\n    \n    #train_w_dict = {}\n    it = len(train_w1)//CHUNK +1\n\n    for i in tqdm(range(it)):\n        if i < it-1: temp = df.iloc[i*CHUNK: (i+1)*CHUNK,:].copy()\n        else: temp = df.iloc[i*CHUNK:,:].copy()\n        temp['input'] = temp.apply(lambda x: x['aid'] + \n                                      list((TRAIN_HISTORY - len(x['aid'])) * [0]), \n                                      axis = 1)\n        temp['target'] = temp.apply(lambda x: x['label'] + \n                                      list((PREDICTION_HISTORY - len(x['aid'])) * [0]), \n                                      axis = 1)\n        \n        temp.drop(['aid', 'label'], axis = 1, inplace = True)\n        temp.to_parquet(f'/kaggle/working/input_target_part_{i}.parquet')\n        \n        #train_w_dict[i] = temp\n        \n        del temp\n\n#     for file in glob.glob(\"/kaggle/working/input_target_part_*.parquet\"):\n#        train_w_dict[file] = pd.read_parquet(file)\n    #df = pd.concat(train_w_dict.values())    \n    #return df\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_w1 = get_input_target(train_w1)\nget_input_target(train_w1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_w1\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_w1 = pd.DataFrame()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for file in glob.glob(\"/kaggle/working/input_target_part_*.parquet\"):\n    temp = pd.read_parquet(file)\n    train_w1 = pd.concat([train_w1, temp], ignore_index = True)  \n    del temp\n    gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}